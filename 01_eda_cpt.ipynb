{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual exploration of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Simple relative path from root directory\n",
    "FILEPATH = Path(\"data/raw/CPT_PremstallerGeotechnik_revised.csv\")\n",
    "df = pd.read_csv(FILEPATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features defined by Rauter and Tschuchnigg (2019). Note: several features are derived feature engineered features.\n",
    "- Derived from other features: 'Rf (%)', 'Qt (-)', 'Qtn (-)', 'Fr (%)'\n",
    "- Calculated: 'γ (kN/m³)', 'σ,v (kPa)',\n",
    "       'u0 (kPa)', 'σ',v (kPa)', 'Depth (m)'\n",
    "- Measured: 'qc (MPa)', 'fs (kPa)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"Depth (m)\",\n",
    "    \"qc (MPa)\",\n",
    "    \"fs (kPa)\",\n",
    "    \"Rf (%)\",\n",
    "    \"σ,v (kPa)\",\n",
    "    \"u0 (kPa)\",\n",
    "    \"σ',v (kPa)\",\n",
    "    \"Qtn (-)\",\n",
    "    \"Fr (%)\",\n",
    "]\n",
    "SITE_INFO = [\"ID\", \"test_type\", \"basin_valley\"]\n",
    "LABELS_O = [\"Oberhollenzer_classes\"]\n",
    "df = df.loc[:, SITE_INFO + FEATURES + LABELS_O]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balance of the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Oberhollenzer_classes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove class 0 since that is a bagging class\n",
    "df = df[df[\"Oberhollenzer_classes\"] != 0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the class numbers to more descriptive names using the Oberhollenzer classification\n",
    "class_mapping = {\n",
    "    1: \"Gravel\",\n",
    "    2: \"Fine grained organic soils\",\n",
    "    3: \"Coarse grained organic soils\",\n",
    "    4: \"Sand to gravel\",\n",
    "    5: \"Sand\",\n",
    "    6: \"Silt to fine sand\",\n",
    "    7: \"Clay to silt\",\n",
    "}\n",
    "# visualise value counts per class\n",
    "df[\"Oberhollenzer_classes\"] = df[\"Oberhollenzer_classes\"].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"basin_valley\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run describe on the numberical features\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "numeric_features = df[FEATURES].select_dtypes(include=[\"number\"]).columns\n",
    "df[numeric_features].describe()\n",
    "# pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ydata-profiling for automated EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = df.copy()[FEATURES + LABELS_O]\n",
    "dfy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(dfy, title=\"Profiling report\")\n",
    "profile.to_file(\"dataset_profiling_cpt.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you need to check in the dataset?\n",
    "- What distributions do the features have?\n",
    "- Are there any missing values?\n",
    "- Are there any duplicates?\n",
    "- Are there any outliers? Be cautious with this one, as outliers can be valid data points.\n",
    "- Are there any relationships between the features? Some features might be removed if they are highly correlated.\n",
    "- Are there any relationships between the features and the target variable? Only in regression.\n",
    "- Are there any relationships between the features and the target variable that are not linear? Only in regression.\n",
    "- Are the labels balanced?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trends in the data\n",
    "- Not normally distributed\n",
    "- Duplicate values\n",
    "- Correlated features\n",
    "- outliers present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=FEATURES)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardcoded values (values that are not possible in the real world) are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded\n",
    "df = df[df[\"qc (MPa)\"] > 0]\n",
    "df = df[df[\"u0 (kPa)\"] >= 0]\n",
    "df = df[df[\"Qtn (-)\"] > 0]\n",
    "df = df[(df[\"fs (kPa)\"] < 1200) & (df[\"fs (kPa)\"] > 0)]\n",
    "# df = df[(df['Rf (%)'] < 10) & (df['Rf (%)'] > 0)]\n",
    "df = df[df[\"Rf (%)\"] > 0]\n",
    "df = df[(df[\"Fr (%)\"] < 10) & (df[\"Fr (%)\"] > 0)]\n",
    "# skip samples with label 3.0\n",
    "# df = df[df['Oberhollenzer_classes'] != 3.0] # due to low sample size\n",
    "# df = df[df[\"Oberhollenzer_classes\"] != 0.0]  # due to low sample size\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate outlier detection - we exemplify for one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"Qtn (-)\"].hist(bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate\n",
    "from pyod.models.mad import MAD\n",
    "\n",
    "threshold = 7.0  # Typical value, can be adjusted for sensitivity\n",
    "mad = MAD(threshold=threshold)\n",
    "\n",
    "# Fit the model on the column\n",
    "mad.fit(df[[\"Qtn (-)\"]])\n",
    "\n",
    "# Predict outliers (1 for outlier, 0 for inlier)\n",
    "outliers = mad.predict(df[[\"Qtn (-)\"]])\n",
    "\n",
    "# Filter the DataFrame to exclude outliers\n",
    "df_no_outliers = df[outliers == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers[\"Qtn (-)\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[FEATURES].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "outlier_confidence_threshold = 0.95  # Adjust threshold for your use case\n",
    "\n",
    "# Initialize and fit the Isolation Forest model\n",
    "iforest = IForest(n_estimators=100)\n",
    "iforest.fit(df[FEATURES])\n",
    "\n",
    "# Get the outlier probabilities\n",
    "probs = iforest.predict_proba(df[FEATURES])[:, 1]\n",
    "\n",
    "# Create a mask for outliers based on the confidence threshold\n",
    "is_outlier = probs > outlier_confidence_threshold\n",
    "outliers = df[is_outlier]\n",
    "non_outliers = df[~is_outlier]\n",
    "\n",
    "# Display results\n",
    "num_outliers = len(outliers)\n",
    "print(f\"Number of outliers with Isolation Forest: {num_outliers}\")\n",
    "print(f\"Percentage of outliers: {num_outliers / len(df):.4f}\")\n",
    "print(\"Outlier samples:\\n\", outliers)\n",
    "\n",
    "# Cleaned DataFrame excluding outliers\n",
    "df_cleaned = df[~is_outlier]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic splitting of the dataset in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_cleaned[FEATURES]\n",
    "y = df_cleaned[\"Oberhollenzer_classes\"]\n",
    "seed = 10\n",
    "test_size = 0.25\n",
    "train, test = train_test_split(\n",
    "    df_cleaned, test_size=test_size, random_state=seed, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the effect of stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Oberhollenzer_classes\"].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Oberhollenzer_classes\"].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical geotechnical problem: data from same borehole should not be split between train and test set. Then there is a risk of data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = df[\"ID\"].unique()\n",
    "train_ids, _ = train_test_split(unique_ids, test_size=test_size, random_state=seed)\n",
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"ID\"].isin(train_ids)]\n",
    "test_df = df[~df[\"ID\"].isin(train_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Oberhollenzer_classes\"].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Oberhollenzer_classes\"].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another round in ydate-profiling with splitted dataset\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "dfy_train = train_df.copy()[FEATURES + LABELS_O]\n",
    "dfy_test = test_df.copy()[FEATURES + LABELS_O]\n",
    "# dfy_train[\"Oberhollenzer_classes\"] = dfy_train[\"Oberhollenzer_classes\"].astype(str)\n",
    "# dfy_test[\"Oberhollenzer_classes\"] = dfy_test[\"Oberhollenzer_classes\"].astype(str)\n",
    "profile_train = ProfileReport(dfy_train, title=\"Profiling report - Train\")\n",
    "profile_test = ProfileReport(dfy_test, title=\"Profiling report - Test\")\n",
    "comparison_report = profile_train.compare(profile_test)\n",
    "comparison_report.to_file(\"dataset_profiling_comparison_cpt.html\")\n",
    "comparison_report.to_notebook_iframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data\n",
    "\n",
    "Save the train and test sets to CSV files for use in model training notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple relative path from root directory\n",
    "output_dir = Path(\"data/model_ready\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save train and test datasets\n",
    "train_df.to_csv(output_dir / \"dataset_train.csv\", index=False)\n",
    "test_df.to_csv(output_dir / \"dataset_test.csv\", index=False)\n",
    "\n",
    "print(f\"Train dataset saved: {train_df.shape[0]} rows, {train_df.shape[1]} columns\")\n",
    "print(f\"Test dataset saved: {test_df.shape[0]} rows, {test_df.shape[1]} columns\")\n",
    "print(f\"Files saved to: {output_dir.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-machine-learning-for-geotechnics-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
