{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Simple relative paths from root directory\n",
    "FILEPATH_TRAIN = Path(\"data/model_ready/dataset_train.csv\")\n",
    "FILEPATH_TEST = Path(\"data/model_ready/dataset_test.csv\")\n",
    "\n",
    "FEATURES = [\n",
    "    \"Depth (m)\",\n",
    "    \"qc (MPa)\",\n",
    "    \"fs (kPa)\",\n",
    "    \"Rf (%)\",\n",
    "    \"Ïƒ,v (kPa)\",\n",
    "    \"u0 (kPa)\",\n",
    "    \"Ïƒ',v (kPa)\",\n",
    "    \"Qtn (-)\",\n",
    "    \"Fr (%)\",\n",
    "]\n",
    "SITE_INFO = [\"ID\", \"test_type\", \"basin_valley\"]\n",
    "LABELS = \"Oberhollenzer_classes\"\n",
    "\n",
    "df_train = pd.read_csv(FILEPATH_TRAIN)\n",
    "df_test = pd.read_csv(FILEPATH_TEST)\n",
    "\n",
    "# only features and labels\n",
    "df_train = df_train.loc[:, FEATURES + [LABELS]]\n",
    "df_test = df_test.loc[:, FEATURES + [LABELS]]\n",
    "\n",
    "# filter class 3.0 as done in the EDA notebook\n",
    "df_train = df_train[df_train[LABELS] != 3.0]\n",
    "df_test = df_test[df_test[LABELS] != 3.0]\n",
    "\n",
    "# get X, y\n",
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train[LABELS]\n",
    "X_test = df_test[FEATURES]\n",
    "y_test = df_test[LABELS]\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring performance boundaries and computational effort\n",
    "\n",
    "We will compare some main groups of models and their performance on the dataset. We will also explore the computational effort required to train and evaluate these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier - an interesting model always need to better than this.\n",
    "\n",
    "**NOTE**: To reference a benchmark model in a scientific paper you should also check if there are other model performance benchmarks relevant on the dataset using other statistical, numerical or mathematical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_model.fit(X_train, y_train)\n",
    "y_pred = dummy_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some new terms from the classification report:\n",
    "- support: number of occurrences of each class in y_true\n",
    "- weighted avg: average of the metrics, weighted by the support values\n",
    "- macro avg: average of the metrics for each class. Macro avg for recall is the same as balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A linear model\n",
    "\n",
    "**NOTE about scaling**: Apart from tree-based models, most models are sensitive to the scaling of the input features. It is a good practice to scale the input features before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(X_train)\n",
    "x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500, random_state=42)\n",
    "lr_model.fit(x_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(x_test_scaled)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "A simple non-linear model which is computationally efficient but often quite powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees (Extremely Randomized Trees)\n",
    "\n",
    "A tree based model which is computationally efficient and often performs better than the classic Random Forest. The main difference to Random Forest is heavier regularization and less variance, leading to less overfitting.\n",
    "\n",
    "Tree-based models do not require scaling of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "et_model.fit(X_train, y_train)\n",
    "y_pred_et = et_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_et))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The classic Random Forest for comparison. Note the extra computational effort required to train and evaluate this model, compared to the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "We complete the exploration by training an XGBoost model. This model is computationally expensive to train and evaluate if you do not have a GPU, but often among the best performing models for tabular data. The other top performing models for tabular data are usually `LightGBM` and `CatBoost`. Usually these tree-based models also perform better than a neural network on tabular data.\n",
    "\n",
    "**NOTE**: XGBoost has a Scikit-learn API (not including GPU support), but the XGBoost library also has a native API which can be used for faster training and evaluation. The implementation below uses the native API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train[LABELS]\n",
    "X_test = df_test[FEATURES]\n",
    "y_test = df_test[LABELS]\n",
    "\n",
    "# Encode the string-based lithology labels so XGBoost can train\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert the balanced training data to DMatrix (with GPU support)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test_encoded)\n",
    "\n",
    "# Set parameters for using GPU with multiclass classification\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",  # Use multiclass objective (softmax or softprob)\n",
    "    \"num_class\": len(label_encoder.classes_),  # Number of classes\n",
    "    \"device\": \"cuda\",  # use cpu if you don't have GPU on the machine\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions (output is directly class labels)\n",
    "y_pred_encoded = xgb_model.predict(dtest)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded.astype(int))\n",
    "y_test_original = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_test_original, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the dataset\n",
    "\n",
    "Since the KNN is computationally efficient and among the better performers, we will use that to exemplify the topics of scaling and balancing the dataset. **NOTE**: The increased score for class 3 is due to the balancing of the dataset.\n",
    "\n",
    "In balancing it might work well to first undersample the majority classes to a certain level and then oversample the minority classes to a certain level. This is a common approach to balance the dataset. The levels are often chosen based on the class distribution in the dataset, and is a hyperparameter that can be tuned.\n",
    "\n",
    "Best practise:\n",
    "\n",
    "- Undersample the majority classes to reduce their dominance, thus addressing computational challenges and ensuring training is not biased towards these classes.\n",
    "- Oversample the minority classes to generate synthetic examples that provide more training data for classes with few samples, thus reducing the risk of the model neglecting them. Do not blindly oversample to the same size as the majority classes, as this can lead to overfitting due to synthetic instances being overly similar to each other. \n",
    "- It is generally advisable to oversample to a level where the minority classes have enough examples to be statistically significant but without creating a perfect balance. For example, aim for the minority class to reach 70-90% of the size of the majority class.\n",
    "- The levels of undersampling and oversampling can be tuned as hyperparameters, using cross-validation to find the best values. Inspect the class distribution in the training set and set some initial levels based on this distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train value counts before undersampling\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the distribution it seems like these levels are ok:\n",
    "- Undersample majority classes to 110 000 samples\n",
    "- Oversample minority classes to 75 000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train[LABELS]\n",
    "X_test = df_test[FEATURES]\n",
    "y_test = df_test[LABELS]\n",
    "\n",
    "# Step 1: Scaling the data\n",
    "scaler = StandardScaler()\n",
    "# Use the pro suffix to indicate that the data is processed, to avoid overwriting the\n",
    "# original data, and to facilitate easy commenting out of the processing steps\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Inspect the initial class distribution\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"Initial class distribution in y_train:\\n\", class_counts)\n",
    "\n",
    "# Set desired levels for undersampling and oversampling\n",
    "undersample_level = (\n",
    "    110000  # Target number of samples for majority classes after undersampling\n",
    ")\n",
    "oversample_level = (\n",
    "    75000  # Target number of samples for minority classes after oversampling\n",
    ")\n",
    "\n",
    "# Define undersampling strategy for RandomUnderSampler\n",
    "majority_classes = class_counts[class_counts > undersample_level].index\n",
    "undersample_dict = dict.fromkeys(majority_classes, undersample_level)\n",
    "\n",
    "# Apply RandomUnderSampler to reduce majority classes\n",
    "undersampler = RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(\n",
    "    X_train_scaled, y_train\n",
    ")\n",
    "\n",
    "# Inspect class distribution after undersampling\n",
    "resampled_class_counts = pd.Series(y_train_resampled).value_counts()\n",
    "print(\"Class distribution after undersampling:\\n\", resampled_class_counts)\n",
    "\n",
    "# Set oversampling strategy for SMOTE using a dictionary\n",
    "# Here, each class below the desired oversample level will be increased to oversample_level\n",
    "oversample_dict = {\n",
    "    cls: oversample_level\n",
    "    for cls in resampled_class_counts.index\n",
    "    if resampled_class_counts[cls] < oversample_level\n",
    "}\n",
    "\n",
    "# Apply SMOTE to oversample minority classes\n",
    "smote = SMOTE(sampling_strategy=oversample_dict, random_state=42)\n",
    "X_train_final, y_train_final = smote.fit_resample(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Inspect class distribution after oversampling\n",
    "final_class_counts = pd.Series(y_train_final).value_counts()\n",
    "print(\"Class distribution after oversampling:\\n\", final_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the scaled and resampled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.DataFrame(X_train_final, columns=FEATURES)\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Step 4: Make predictions and evaluate\n",
    "y_pred_final = knn_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for training and evaluation\n",
    "To avoid data leakage and for a more condense implementation we use a `Pipeline` from `sklearn`. Since we use `SMOTE` for balancing the dataset, we need to use the `imbalanced-learn` version of the `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define feature and label sets\n",
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train[LABELS]\n",
    "X_test = df_test[FEATURES]\n",
    "y_test = df_test[LABELS]\n",
    "\n",
    "# Set desired levels for undersampling and oversampling\n",
    "undersample_level = 110000\n",
    "oversample_level = 75000\n",
    "\n",
    "# Define undersampling strategy\n",
    "undersample_dict = {\n",
    "    cls: undersample_level\n",
    "    for cls in y_train.value_counts().index\n",
    "    if y_train.value_counts()[cls] > undersample_level\n",
    "}\n",
    "\n",
    "# Define oversampling strategy\n",
    "oversample_dict = {\n",
    "    cls: oversample_level\n",
    "    for cls in y_train.value_counts().index\n",
    "    if y_train.value_counts()[cls] < oversample_level\n",
    "}\n",
    "\n",
    "\n",
    "# Create pipeline for preprocessing and model fitting\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomUnderSampler(sampling_strategy=undersample_dict, random_state=42),\n",
    "    SMOTE(sampling_strategy=oversample_dict, random_state=42),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_final = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Compute confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_final, normalize=\"true\")\n",
    "\n",
    "# Visualise the confusion matrix in the standard scikit-learn way\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=conf_matrix, display_labels=knn_model.classes_\n",
    ")\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A code version with enhanced visualisation of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional function to make the CM prettier.\n",
    "import numpy as np\n",
    "def add_black_grid_lines(ax):\n",
    "    \"\"\"\n",
    "    Adds black grid lines around each square in the confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    ax (matplotlib.axes._axes.Axes): The axes object of the plot.\n",
    "    \"\"\"\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_edgecolor(\"black\")\n",
    "    ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "    ax.set_xticks(np.arange(conf_matrix.shape[1]) + 0.5, minor=True)\n",
    "    ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=True)\n",
    "    ax.tick_params(which=\"minor\", size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# Mapping table of class names with updated ordering\n",
    "# The table is reordered to better match the physical properties of the soils\n",
    "soil_classification = {\n",
    "    1: \"gravel\",\n",
    "    4: \"sand to gravel\",\n",
    "    5: \"sand\",\n",
    "    3: \"coarse grained organic soils\",\n",
    "    2: \"fine grained organic soils\",\n",
    "    6: \"silt to fine sand\",\n",
    "    7: \"clay to silt\",\n",
    "}\n",
    "\n",
    "# Update the labels using the mapping table with map function\n",
    "class_labels = list(soil_classification.values())\n",
    "\n",
    "# Generate the confusion matrix with labels in the desired order\n",
    "class_label_numbers = list(soil_classification.keys())\n",
    "conf_matrix = confusion_matrix(\n",
    "    y_test, y_pred_final, labels=class_label_numbers, normalize=\"true\"\n",
    ")\n",
    "\n",
    "# Round the values in the confusion matrix to a maximum of 3 digits behind the comma\n",
    "conf_matrix = np.round(conf_matrix, 3)\n",
    "\n",
    "# Visualise the confusion matrix with an optional thin black line around each square\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "disp.plot(cmap=\"Blues\", ax=ax, colorbar=False)\n",
    "\n",
    "# Toggle black grid lines on or off\n",
    "add_black_lines = True\n",
    "if add_black_lines:\n",
    "    add_black_grid_lines(ax)\n",
    "\n",
    "# Ensure labels align correctly with ticks\n",
    "ax.set_xticks(np.arange(len(class_labels)))\n",
    "ax.set_xticklabels(class_labels, rotation=45, ha=\"right\")\n",
    "ax.set_yticks(np.arange(len(class_labels)))\n",
    "ax.set_yticklabels(class_labels)\n",
    "\n",
    "plt.title(\"Confusion Matrix (recall for each class on the diagonal)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation with a standard stratified k-fold splitter (wrong version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "# make df_full by combining train and test sets\n",
    "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "\n",
    "X_combined = df_full[FEATURES]\n",
    "y_combined = df_full[LABELS]\n",
    "\n",
    "# Create pipeline for scaling, oversampling, and KNN model\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SMOTE(random_state=42, sampling_strategy=\"auto\"),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    ")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = [\"balanced_accuracy\", \"precision_macro\", \"recall_macro\", \"accuracy\"]\n",
    "cross_val_results = cross_validate(\n",
    "    pipeline, X_combined, y_combined, cv=cv, scoring=scoring\n",
    ")\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(\"Balanced Accuracy:\", cross_val_results[\"test_balanced_accuracy\"].mean())\n",
    "print(\"Precision:\", cross_val_results[\"test_precision_macro\"].mean())\n",
    "print(\"Recall:\", cross_val_results[\"test_recall_macro\"].mean())\n",
    "print(\"Accuracy:\", cross_val_results[\"test_accuracy\"].mean())\n",
    "\n",
    "# print all values for balanced accuracy\n",
    "print(cross_val_results[\"test_balanced_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New try with a grouped splitter which dont split the same drillhole in train and test set (correct version for this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, cross_validate\n",
    "\n",
    "# make df_full by combining train and test sets\n",
    "df_train = pd.read_csv(FILEPATH_TRAIN)\n",
    "df_test = pd.read_csv(FILEPATH_TEST)\n",
    "\n",
    "# only features and labels\n",
    "df_train = df_train.loc[:, FEATURES + [LABELS] + [\"ID\"]]\n",
    "df_test = df_test.loc[:, FEATURES + [LABELS] + [\"ID\"]]\n",
    "\n",
    "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "y_combined = df_full[LABELS]\n",
    "\n",
    "groups = df_full[\"ID\"]  # Use the drillhole ID to group the data\n",
    "\n",
    "# Drop the ID column for training\n",
    "X_combined = df_full[FEATURES]\n",
    "\n",
    "# Create pipeline for scaling, oversampling, and KNN model\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SMOTE(random_state=42, sampling_strategy=\"auto\"),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    ")\n",
    "\n",
    "# Perform cross-validation using GroupKFold to ensure no drillhole is split between train and test\n",
    "cv = GroupKFold(n_splits=5)\n",
    "scoring = [\"balanced_accuracy\", \"precision_macro\", \"recall_macro\", \"accuracy\"]\n",
    "cross_val_results = cross_validate(\n",
    "    pipeline, X_combined, y_combined, cv=cv, groups=groups, scoring=scoring\n",
    ")\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(\"Balanced Accuracy:\", cross_val_results[\"test_balanced_accuracy\"].mean())\n",
    "print(\"Precision:\", cross_val_results[\"test_precision_macro\"].mean())\n",
    "print(\"Recall:\", cross_val_results[\"test_recall_macro\"].mean())\n",
    "print(\"Accuracy:\", cross_val_results[\"test_accuracy\"].mean())\n",
    "\n",
    "# print all values for balanced accuracy\n",
    "print(cross_val_results[\"test_balanced_accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-machine-learning-for-geotechnics-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
